---
layout: post
title:  2021년 6월 머신러닝파트 월간 리뷰
date:   2021-06-05 00:00:00 +0900
author: 전지호
tags: monthlyreport
excerpt: 과금넛지와 디지털사이니지, 오프라인 광고지역 선정에 대한 리뷰입니다.
use_math: false
toc: false
# tags: 자동 수집되는 태그 띄어쓰기로 구분, 반드시 소문자로 사용
# excerpt: 메인 화면에 노출되는 post의 description
# use_math : 수식이 필요 할 경우(윗 첨자, 아랫첨자 동시 사용 불가) true | false
# toc : 목차가 필요 할 경우 true | false
# emoji 사이트: https://getemoji.com/
# 수정사항
# 1. 과금넛지
# 1-1. 모델피팅 목적 항목
# 1-2. 오차그래프 큰 이미지로 변경
# 1-3. Cashflow 데이터 EDA 항목 추가
# 2. 디지털사이니지
# 2-1. FacialExpression 항목 추가
# 2-2. Idendification 동영상 Gif 이미지로 변경하여 삽입.
# 3. 머신러닝파이프라인
# 3-1. 설명을 위해 외부 레퍼런스 이미지 삽입
---


# 과금넛지

<hr/>

> 5차 실험 집행 후, 넛지 대상자의 반응 여부를 판단하기 위해 충전액 예측 모델링을 진행 중입니다.
>> <u>넛지 전후 충전액을 예측</u>하여 유저의 반응 여부와 효과를 측정하기 위함입니다.

4월 리뷰 당시보다 효율적인 효과측정을 위해, 더 고도화된 모델링이 필요하다고 판단했습니다.

<br/>

## 1차 충전액 예측 모델링의 과정

<hr/>

> 1차에서 4차까지의 실험 결과와 Nxlog를 바탕으로 Feature를 만들어 여러가지 예측 모델에 집어넣어 성능을 평가했습니다.

### Feature Extraction

충전액을 예측할 수 있는 Feature를 분류별로 추출해보았습니다.

첫 번째, `접속, 충전, 구매`와 관련한 Features입니다.
- 접속횟수, 플레이타임, 미접속일수 등 접속 관련 세부 정보
- 구매횟수, 구매액 등 구매 관련 세부 정보
- 충전횟수, 충전액 등 충전 관련 세부 정보

두 번째, `인구 통계`와 관련한 Features입니다.
- 성별, 나이
- 아이템 관련
    - PCA 기반 아이템 그룹 구매 count
        - (상위 100개 아이템 기준) 유저 아이템 메트릭스를 이용해 PCA로 item 그룹 생성
    - 유저별 아이템 구매 경험 및 가격
        - 아이템 평균 가격, 평균 구매 가격, main 아이템 구매 여부 및 수량, 고가치 아이템 구매 여부 및 수량
- 캐시샵 방문 관련
    - 과거 방문횟수, 방문일수 등 관련 세부 정보

<br/>

### Model Fitting

목적??
- 유저별 30일간의 충전량 예측
사용 데이터
- 모델링 과정의 데이터는 대조군만을 사용 (넛지에 오염되지 않은 실험대상)
- 초반 과금량 분포를 보고, 전체 유저의 10퍼센트 정도의 상위 outlier 제거
    - outlier로 인해 오차가 커지는 것을 방지
    - 전반적으로 과소추정하는 모델을 만들기 위함

lightGBM
- binary 
    - 약 75만 유저 중 46만이 무과금 유저로, 대부분 0(무과금)으로 예측하는 문제 발생
    - binary model로 무과금 유저를 걸러낸 후, regression model을 사용하여 오차를 줄이면서 동시에 납득할만한 예측치를 얻고자 함
    - 보수적인 예측을 위해 label 1 (실제 과금 유저)에 대한 recall (실제 과금 유저를 과금으로 예측하는 것)을 스코어로 사용
        - 이를 통해, 과금 가능성이 조금이라도 보이는 유저는 걸러지지 않음
    - label 1에 대한 recall 0.9, 0에 대한 recall 0.5 전후를 보임
- regression
    - MAPE 최소화 LightGBM 회귀 모델
        - 모델 예측값이 대부분 0인 문제를 보임
    - MSE 최소화 LightGBM 회귀 모델
        - 과금이 높은 유저에 대한 오차 패널티를 증대하여, 모델 예측값이 대부분 0인 문제를 완화하려는 시도
        - MAPE 최소화 LightGBM 회귀 모델에 비해 과금량이 많은 유저에 대한 오차가 상대적으로 작지만, 여전히 대부분 예측값이 0인 문제 잔재
    - binary 분류 → MAPE & MSE 최소화 LightGBM 회귀 모델
        - 모델의 예측값이 대부분 0인 문제를 해결하기 위해, binary 분류 모델이 과금 유저라고 예측한 데이터만 사용하여 모델 트레이닝
        - 분류 모델이 과금 유저라고 예측한 유저의 약 50%는 무과금 유저였고, 예측된 과금량은 여전히 대부분 0으로 예측
        - 백분률 변환과 log 변환을 시도하였으나 큰 변화 없음

KNN
- Base model을 위한 KNN
    - 기존 모델과의 성능 비교를 위한 모델
- 과금 여부 예측 이진 분류 LightGBM 모델 → KNN 회귀 모델
    - 과금 여부 예측 이진 분류 모델이 1(과금 유저)로 예측한 데이터에 한해서 KNN 회귀 모델 적용
    - 여전히 예측값이 0에 가까운 문제

<br/>

### Evaluation

다음과 같은 성능을 보였습니다.

| Model                                                        | alias                | MAE     | MAPE (+1000후 계산) |
| :----------------------------------------------------------- | :------------------- | :------ | :------------------------- |
| Baseline KNN                                                 | base_knn_model       | 15960원 | 671.80%             |
| MAPE 최소화 LightGBM 회귀 모델                               | mape_model           | 14694원 | 27.88%              |
| MSE 최소화 LightGBM 회귀 모델                                | mse_model            | 16035원 | 688.66%             |
| 과금 여부 예측 이진 분류 LightGBM 모델 → MAPE 최소화 LightGBM 회귀 모델 | bin_mape_model       | 14582원 | 54.01%              |
| 과금 여부 예측 이진 분류 LightGBM 모델 → MSE 최소화 LightGBM 회귀 모델 | bin_mse_model        | 13799원 | 485.77%             |
| 과금 여부 예측 이진 분류 LightGBM 모델 → Log 변환 후  MSE 최소화 LightGBM 회귀 모델 | bin_log_mse_model    | 15003원 | 44.52%              |
| 과금 여부 예측 이진 분류 LightGBM 모델 → 백분률 변환 후 MSE 최소화 LightGBM 회귀 모델 | bin_minmax_mse_model | 13450원 | 469.54%             |
| 과금 여부 예측 이진 분류 LightGBM 모델 → 백분률 변환 후 MAE 최소화 LightGBM 회귀 모델 | bin_minmax_mae_model | 12056원 | 177.27%             |
| 과금 여부 예측 이진 분류 LightGBM 모델 → KNN 회귀모델        | bin_knn_model        | 14971원 | 556.93%             |


![오차 그래프 1](https://solution-userstats.s3.ap-northeast-1.amazonaws.com/techblogs/yeonsuuu/y_pred_error1.png){: #popup }

![오차 그래프 2](https://solution-userstats.s3.ap-northeast-1.amazonaws.com/techblogs/yeonsuuu/y_pred_error2.png){: #popup }

<br/>

## 1차 충전액 예측 모델링의 결론

<hr/>

> 5차 실험을 진행하기에, 1차 충전액 예측 모델링은 <u>충분하지 못한 성능</u>이 나왔습니다.

대부분의 값을 0의로 예측했고, 충전여부를 예측하는 분류모델도 제대로 작동하지 않았습니다.

<u><b>모델 성능에 문제가 있었던 점을 다음 3가지로 예상하고 있습니다.</b></u>

- 모델에 충분한 정보를 주지 않음
    - 추가 feature 생성
        - 개별 게임에 종속된 정보
        - cashflow에서 얻을 수 있는 정보
        - 시계열 모델 예측결과 및 embedding
- 관찰기간인 30일 간, 발생하는 외부 이벤트가 유저 구매행동에 영향을 줌
    - 구매 행동에 영향을 줄 수 있는 외부 이벤트: 이탈, 게임 내 여론 변화, 확률형 아이템의 사용결과(운) 등등
    - 모델에 가능한 한 많은 정보를 제공했음에도 스코어가 개선되지 않을 때 의심할 것
- 유저의 구매행동이 충동적으로 일어나므로 예측이 불가
    - <u><b>위의 모든 가능성을 다 탐색했음에도 모델 성능이 충분히 나오지 않을 경우, 예측이 불가능한 것으로 간주할 예정</b></u>
- `Cashflow의 데이터의 이상`
    - Cashflow의 데이터의 이상이 있었지만, 해결완료.

<br/>

## Cashflow 데이터 EDA

<hr/>

<br/>

## 과금넛지 6월 계획

<hr/>

과금넛지 프로젝트 6월 계획은 다음과 같습니다.

- 효과측정 도구 개발 
    - 두번째 루프로 진입하여 가설을 검증하고, 개발이 가능한지 확인
- 새로운 넛지 시나리오 기획
    - 충전액이 늘어나도록 유도하는 넛지
        - 넛징을 받는 유저가 스스로 운이 좋다고 느끼게 하기
        - 넛징으로 캐시 관련 자극을 반복적으로 받도록 설계하기
    - 충전하는 주기가 짧아지도록 유도하는 넛지

<br/>

# 디지털 사이니지

<hr/>

> 디지털사이니지 마일스톤 중 FGT 웹 솔루션 제작 단계에 곧 돌입합니다. 또한, 아이덴티피케이션 모델 개발에 착수 했습니다.

<br/>

## 넥슨 퍼스트 관련 헙업 문서 제안

<hr/>

👉 [<u>협업 제안서</u>](https://naver.com)

넥슨 퍼스트 관련 향후 문제점이 될 만한 요소들은 다음과 같습니다.

- 테스트 유저가 노출을 원하지 않거나, 모바일 테스트 시 카메라를 가리는 이슈
    - 카메라 노출 시, 추가적인 혜택을 주는 방안을 고려
- 관련 분석을 어떻게 활용할 수 있을 지에 대한 인사이트 부족
    - 데이터 분석가의 리포트를 통해 인사이트를 줄 수 있는 방안을 고려
- 넥슨 퍼스트의 확정되지 않은 개발 기간
    - Dependency를 줄이는 방안으로 개발

따라서 넥슨 퍼스트와는 별도로 `데모 분석 리포트`와 `데모 웹 콘솔`을 제작해 추후 시연하는 방식으로 협의가 이루어 졌습니다.

추가로 UX실에서 25G 용량의 게임 플레이 동영상을 제공해주었고, 이를 모델 개발과 리포트 개발에 활용했습니다.

## FacialExpression 모델 개발

<hr/>

> 영상을 통해 감정을 추론하는 모델은 목표로 했던 수준의 <u>개발이 완료</u>되어, <u>추론 결과를 바탕으로 리포트</u>를 개발 중입니다.

<br/>

## Identification 모델 개발

<hr/>

> 오프라인 광고 집행 시, <u>사람들이 해당 광고를 얼마나 관심있게 봤는 가</u>를 측정하기 위함입니다.

<br/>

### Object Detection

> <u>몇명의 사람들이 광고앞에 있는가</u>를 알기 위해 Object Detection 모델을 먼저 연구했습니다.

첫 연구에 사용될 모델을 선정했던 기준은 다음과 같습니다.

- `Tensorflow 기반 모델`
- 👉 [<u>Tensorflow2 Object Detection Model zoo</u>](https://github.com/tensorflow/models/tree/master/research/object_detection)
- 비교적 최근 모델
- 해상도가 높은 모델(1024x1024) 

테스트에 사용된 모델들은 다음과 같습니다.

+ CenterNet HourGlass104 1024x1024 (CenterNet)
+ EfficientDet D4 1024x1024 (EfficientDet)
+ SSD MobileNet V2 FPNLite 640x640 (MobileNet)
+ SSD ResNet152 FPN 1024x1024 (RetinaNet)
+ Fast R-CNN ResNet152 V1 1024x1024 (Fast R-CNN)
+ Mask R-CNN Inception ResNet V2 1024x1024 (Mask R-CNN)

<br/>

### Test

👉 [<u>테스트 영상 링크</u>](https://solution-userstats.s3.ap-northeast-1.amazonaws.com/techblogs/hgchoi16/4k-002.mkv)

<br/>

### Evaluation

선정된 모델의 테스트 결과, 다음과 같은 성능을 보였습니다.

|MODEL |     사 |  람    |   찾   |   은     |  수    |  속도|
|------|--------|--------|--------|---------|--------|---------|
|      | Image1 | Image2 | Image3 | Image 4 | Image 5|동영상전체|
|CenterNet|  10   |   10     |    9    |    6     |  6      |130.68s|
|EfficientDet| 9   |    9    |    9    |    7     |  9    |608.38s|
|MobileNet| 1   |    3    |   1    |   4     |   4    |293.48s|
|RetinaNet| 4   |    5    |    1    |   3      |    8    |514.89s
|Fast R-CNN|  12  |   12    |   16     |    10     |   9     |201.66s|
|Mast R-CNN|  12  |    12    |  14      |     10    |    10    |311.81s|

위의 결과에 대한 분석은 다음과 같습니다.

- 기존 논문에서 조사한대로 R-CNN의 성능이 우수한 것이 확인
- 의야한 결과는 원래 SSD 계열들이 속도가 빠르게 나와야하는데 정확도와 속도 측면에서 이상 결과를 보임
    - 구현된 다른 모델들을 찾아보고 보충실험을 필요
- 속도가 가장 빠른 모델은 CenterNet
- 추가적으로 Yolo 계열와 SSD 모델을 새로 찾아서 추가 실험을 진행해야하겠다.

<br/>

## 디지털 사이니지 6월 계획

<hr/>

디지털 사이니지 프로젝트 6월 계획은 다음과 같습니다.

- FacialExpression 모델 기반 데모 리포트 완료 및 UX실 공유
- 감정 리포트 프론트엔드 콘솔 구현
- `Pytorch Identification 기반 모델` 연구

<br/>

# 머신러닝 파이프라인

<hr/>

> 머신러닝파트는 1년 간 머신러닝 서비스 운영 기술적 노하우를 축적하려 노력했습니다. 공유할 수 있는 결과물이 나오기 시작했습니다.

<br/>

## 첫 번째, 자체 BI를 도입했습니다. 쿠버네티스 기반의 JupyterHub를 구축했습니다.

<hr/>

현재, 랩스내 많은 분석 조직에서 `EC2 기반 EMR 제플린`을 사용하고 있습니다.

마케팅 개발실내에서는 컨텐츠 서비스 개발팀, ADS 개발팀이 그러합니다.

`단일 서버 프로세스`를 사용하는 제플린은 많은 사용자가 동시 사용에 사용할 수 있으나,

<u><b>일부 작업이 리소스가 많이 필요할 경우, 전체 리소스에 영향을 주어 다른 작업자의 작업을 방해하는 경우가 많습니다.</b></u>

최악의 경우, 제플린 서버의 프로세스가 멈추어, EC2를 재시작하는 경우가 많습니다.

때문에, 작업자마다 완전히 분리된 독립적인 분석 환경과 테스트 환경을 제공해줘야 합니다.

머신러닝 파트는 쿠버네티스 기반의 JupyterHub를 구축하여 가능하게 했습니다.

<br/>

👉 [<u>머신러닝파트 주피터 허브</u>](http://mlhub.na.nexon.co.kr)

👉 [<u>제플린과 주피터의 비교</u>](/2021/06/03/ApacheZeppelinVsJupyter-전지호.html)

<br/>

쿠버네티스 기반의 주피터허브는 사용자가 로그인 시, 그때마다 독립적인 도커 컨테이너를 만듭니다.

독립된 컨테이너에서 실행되는 작업이 리소스가 부족해 폭파되더라도, 다른 컨테이너에 영향을 줄 수 없습니다.

각 컨테이너마다 분석에 쓰이고자 하는 라이브러리 사양을 골라서 만들수 있고, 해당 컨테이너는 커스터 마이징이 가능합니다.

머신러닝파트는

- Nxlog에 접근할 수 있는 Hadoop 기반의 pyspark 컨테이너
- Pytorch 컨테이너
- Tensorflow 컨테이너

3개의 컨테이너를 내부 사양에 맞게 커스터마이징하여 사용하고 있습니다.

10분 간, 사용하지 않는 컨테이너는 자동으로 내려갑니다. 따라서 쿠버네티스내 컴퓨팅 리소스는 효율적으로 관리됩니다.

전 세계에서 가장 유명한 머신러닝와 데이터 분석도구인 kubeflow, sagemaker, 데이터브릭스에서 제공하는 기능입니다.

기술 공유를 통해 각 조직마다 구축해 내부적으로 사용할 수 있을 것으로 생각합니다.

<br/>

## 두 번째, MLOps CI/CD를 도입했습니다.

<hr/>

아시다시피, 일반 웹서비스처럼 머신러닝 혹은 분석 서비스 또한 라이브 레벨에서는 많은 유지 보수의 비용이 들어갑니다.

현재의 경우처럼 Job을 만들어 airflow로 실행하는 형태의 업무는 실제 대규모 서비스 레벨에 올라갈 경우, 많은 문제를 야기할 수 있습니다.

일단, `형상관리`가 되지 않습니다. 

작업자가 실수를 범하여 서비스 단계에 잘못된 소스가 올라갈 경우, 

롤백에 취약하고 최악의 경우에 이전 코드를 찾을 수 없는 문제가 발생할 수 있습니다.

공동 작업의 경우, 코드를 수정한 사람이나, 배포를 한 사람을 찾아내기 힘들 수도 있습니다.

서든어택 월핵탐지기 경우처럼 다른 조직과 협업하여 하루에 수십만 건 이미지를 머신러닝 코드로 처리하는 프로세스와 같은 서비스가 있다면, 

이러한 취약점은 감당하기 힘든 문제로 돌아올 수 도 있습니다. 

인텔리전스랩스의 분석 및 머신러닝 서비스가 네이버페이, 카카오페이같은 일반 사용자 대상 금융 서비스라고 가정하면 대부분의 분석 서비스가 큰 어려움을 겪을 것이라고 쉽게 생각할 수 있습니다.

그렇기 때문에, 머신러닝 파이프라인에 MLOps라 불리는 CI/CD를 적용했습니다.

현재 `월핵탐지`와 `FGT 감정추론`의 경우,

<u><b>개발자의 도움없이 작업자가 코드만 수정하여 배포, 롤백, 형상관리, 모니터링이 모두 가능합니다.</b></u>

<br/>

👉 [<u>월핵탐지기 모니터링 ArgoCD</u>](https://a4b2cf330e1d2464a951ba793aaae70e-596153973.ap-northeast-2.elb.amazonaws.com/)

👉 [<u>FGT 실시간 감정추론 모니터링 ArgoCD</u>](https://ad1f03f16a72740d68c582a87b928f1b-1924335043.ap-northeast-2.elb.amazonaws.com/)

<br/>

# 옥외광고 지역 선정

<hr/>

> 넥슨 유저의 위치정보 기반의 지역을 선정하다가 위치 기반 데이터의 한계를 느끼고 옥외 광고의 성과를 추적할 수 있는 새로운 아이데이션을 시도했습니다.

<br/>

👉 [<u>옥외광고 지역 선정</u>](https://naver.com)

👉 [<u>[아이데이션]옥외광고소재와 성과측정</u>](https://naver.com)

<br/>

# 상시 업무

<hr/>

> 넥슨과 인텔리전스랩스에 도움이 되는 업무를 지속적으로 하고 있습니다.

- 카트라이더 리그 지원
- 카트라이더 TMI 운영 및 리소스 업데이트
- 월핵탐지기 운영 및 요청사항 반영
- 사내 기술 블로그 운영
- NDC 2021 발표(권승진)
- FGT 관련 논문 작업 중(권승진)