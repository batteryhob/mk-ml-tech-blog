---
layout: post
title:  월말보고(5월)- 최혁근
date:   2021-06-04 00:00:00 +0900
author: 최혁근
tags: computervision objectdetection
excerpt: 5월 보고용 자료입니다.
use_math: true
toc: false
# tags: 자동 수집되는 태그 띄어쓰기로 구분, 반드시 소문자로 사용
# excerpt: 메인 화면에 노출되는 post의 description
# use_math : 수식이 필요 할 경우(윗 첨자, 아랫첨자 동시 사용 불가) true | false
# toc : 목차가 필요 할 경우 true | false
# emoji 사이트: https://getemoji.com/
---

# Face Identification 시스템

## Face Identification 시스템
### 개요
1. 필요성
    * 오프라인 광고측정의 첫걸음
    * 사람들은
        * 광고를 얼마나 보는가?
        * 얼마나 집중하는가?
    * 이런 것을 어떻게 측정할 것인가?
        * **카메라 + 얼굴인식으로 이걸 파악해보자**

2. 방법
    * 카메라가 설치된 디지털 전광판에 광고를 송출
        - 광고는 태그와 메타데이터로 어떤 종류의 광고인지 추적 가능
    * 광고 송출중에 카메라 앞으로 다니는 사람들을 파악
        - 화면에 잡힌 사람들을 개별적으로 인식
        - DB에서 사람들을 누구인지 특징 / 추가 / 추적
        - 사람들이 광고에 시청여부 판단
        - 사람들의 집중시간 판단
    * 광고별 시청률 / 집중률 등등 통계자료를 report
    * 관리자 모드에는 실시간 관찰 UI

3. 세부기능 & 기술스택
    * 사람 인식
        - Object Detection
        - Human Detecetion
    * 얼굴 인식
        - Face Detection
    * 사람 분류 
        - Face embedding
        - Face Verification / Identification
        - Similarity
    * 광고시청 / 집중
        * Head Pose Estimation
        * Eye tracking
        * Engagement detection
    * 사람 정보 저장
        - ID
        - 방문횟수
        - 머문 시간
        - 시청한 시간
        - 사진정보
    
4. 요구사항
    * 성능
    * 속도
    * 장비
    * 환경

5. 일정
    * 개발
    * 서베이
        - 기술
        - 논문
        - 기타
    * 문제점 분석


### 시스템 세부사항
1. 카메라 대기 (동영상으로도 테스트 가능)
    * Cam에서 영상을 프레임 단위로 분리 / 이미지화
    * *화질 / 영상 사이즈 고려*
2. 화면에서 사람 / 얼굴 인식
    * Object Detection
    * Face Detection
3. 사람 ID 확인
    * 얼굴 사진을 embedding해서 vector로 변환
    * 기존 DB에 similarity 계산, 유사도가 높은 순 정리
    * Top1, Top5 등등을 통해서 사람 선별 기준 확립
    * 얼굴이 아닌 사람 전체 모습을 통해서 이전 프레임과의 연관성을 통해 
4. Tracking
    * 확인한 사람을 frame단위로 계속 마킹해준다.

### 추가적으로 리서치가 필요한 분야
* Human Pose Estimation
    - [AlphaPose](https://github.com/MVIG-SJTU/AlphaPose)
    - [Detect And Track](https://github.com/facebookresearch/DetectAndTrack)
* Object Tracking

## Research1 : Object Detection
### 개요
* 사람을 인식하기 위해서는 기존의 물체 인식 (Object Detection) 모델들을 사용한다.
* 실시간으로 진행하기 위해서는 추론 속도가, 후처리를 하기 위해서는 정확도가 중요하다.
* 연구된 여러 가지 구현체들을 실험용 데모영상을 이용해서 정확도와 속도를 측정하고
* 우리 시스템에 어울리는 모델이 무엇일지를 선별한다.

### 실험설계
* 테스트 데이터
    - 동영상 파일        
    - 가장 일반적인 거리영상인 지하철입구 영상
    - 많은 사람들이 지나다닐 때 사람들을 정확히 포착할 수 있는가?
* 테스트 동영상 [링크](https://solution-userstats.s3.ap-northeast-1.amazonaws.com/techblogs/hgchoi16/4k-002.mkv)
    

## 1-1. Tensorflow Object Detection Zoo
### 1. 테스트 개요
* 테스트 모델
    - Object Detection 6가지 모델
        - [Tensorflow2 Object Detection Model zoo](https://github.com/tensorflow/models/tree/master/research/object_detection)
        - 기존에 한번식 break-through를 만들어냈던 모델들
        - 최근 소개된 모델들도 추가해서
        - 해상도가 높은 모델들 선정 (1024x1024)
    - 선정된 모델들
        + CenterNet HourGlass104 1024x1024 (CenterNet)
        + EfficientDet D4 1024x1024 (EfficientDet)
        + SSD MobileNet V2 FPNLite 640x640 (MobileNet)
        + SSD ResNet152 FPN 1024x1024 (RetinaNet)
        + Fast R-CNN ResNet152 V1 1024x1024 (Fast R-CNN)
        + Mask R-CNN Inception ResNet V2 1024x1024 (Mask R-CNN)
* 테스트 방법
    1. 정확도 테스트
        * 임의로 선별한 몇 개의 이미지에 대해서
        * 개별 모델을 실행해서 물체를 인식하고
        * 그 중에서 사람으로 판단하는 확률이 50% 이상인 결과들에 대해서
        * Box 표시하고 이미지로 출력
        * 몇 명이나 사람을 찾아냈는지, 잘못 인식한 것은 얼마나 되는지 확인
    2. 추론 속도 테스트
        * 동영상 전체를(10초, 600 frams)
        * 프레임별로 읽으면서
        * 모델 추론을 진행하고 결과를 확인해보는 방식
        * 추론 시 batchsize를 1, 5로 변화시켜가면서 시간 확인
* 이렇게 테스트를 해보고 우리 환경에 맞는 모델을 선정하는 것이 목표

### 2. 사람인식 테스트

|MODEL |     사 |  람    |   찾   |   은     |  수    |  속도|
|------|--------|--------|--------|---------|--------|---------|
|      | Image1 | Image2 | Image3 | Image 4 | Image 5|동영상전체|
|CenterNet|  10   |   10     |    9    |    6     |  6      |130.68s|
|EfficientDet| 9   |    9    |    9    |    7     |  9    |608.38s|
|MobileNet| 1   |    3    |   1    |   4     |   4    |293.48s|
|RetinaNet| 4   |    5    |    1    |   3      |    8    |514.89s
|Fast R-CNN|  12  |   12    |   16     |    10     |   9     |201.66s|
|Mast R-CNN|  12  |    12    |  14      |     10    |    10    |311.81s|

* 테스트결과 (TODO : 링크주소 수정)
    - Image1
    ![테스트결과1](https://solution-userstats.s3.ap-northeast-1.amazonaws.com/techblogs/hgchoi16/test_result1.png){: #popup }
    - Image2
    ![테스트결과2](https://solution-userstats.s3.ap-northeast-1.amazonaws.com/techblogs/hgchoi16/test_result2.png){: #popup }
    - Image3
    ![테스트결과3](https://solution-userstats.s3.ap-northeast-1.amazonaws.com/techblogs/hgchoi16/test_result3.png){: #popup }
    - Image4
    ![테스트결과4](https://solution-userstats.s3.ap-northeast-1.amazonaws.com/techblogs/hgchoi16/test_result4.png){: #popup }
    - Image5
    ![테스트결과5](https://solution-userstats.s3.ap-northeast-1.amazonaws.com/techblogs/hgchoi16/test_result5.png){: #popup }

### 3. 결과분석 및 여담
* 기존 논문에서 조사한대로 R-CNN의 성능이 우수한 것이 확인됌
* 의야한 결과는 원래 SSD 계열들이 속도가 빠르게 나와야하는데 정확도와 속도 측면에서 결과가 이상해보인다.
    - 구현된 다른 모델들을 찾아보고 보충실험을 진행해봐야하겠다.
* CenterNet의 경우도 좋은 성능을 보여주고 있다. 이번 실험에서는 속도도 가장 빨랐다.
* 추가적으로 Yolo계열와 SSD 모델을 새로 찾아서 추가실험을 진행해야하겠다.
* 이 모델에 추가해서 얼굴인식 모델들도 결합해서 함께 진행해보자!

### 4. 앞으로 진행해야할 내용
1. Pytorch 모델들 조사
    - 간단하게 테스트해본 결과
    - 이쪽 모델들이 사용하거나 변형하기가 훨씬 쉬어보인다.
    - 제일 기본적인 예제 - [TORCHVISION OBJECT DETECTION FINETUNING TUTORIAL](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html#torchvision-object-detection-finetuning-tutorial)
        + 이런 식으로 사람만을 대상으로하는 detection 모델 개발 가능
2. 다른 기법들 조사 및 적용
3. 자체 학습하면 어떻게 데이터를 구하고 어떻게 사용

## 1-2. Pytorch Test
* 현재 진행중
* torchvision에서 기본으로 제공되는 모델이 
    * Mask R-CNN ResNet50 FPN
    * Tensorflow의 Mask R-CNN에서 backbone architecture로 사용된 Inception ResNet V2 1024x1024보다 가벼운 모델
    * 이 모델 최상단에 추가로 Layer를 하나 더 두고 Person Class만을 따로 디텍션하도록 fine tuning 하는 tutorial이 존재
    * 이 과정만으로도 훨씬 무거운 tensorflow모델보다 빠르고 비슷한 성능을 보이는 것으로 확인됨
* 모델 다루기나 코딩도 pytorch 쪽이 훨씬 편리하기 때문에 이걸 중심으로 개발 진행
    * 대신 성능 관련해서는 확실하게 문서화 진행 예정