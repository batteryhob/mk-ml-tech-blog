---
layout: post
title:  Spark broadcastingì„ ì´ìš©í•´ ê¸°ì¡´ ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì†ë„ ê°œì„ í•˜ê¸°
date:   2021-05-31 00:00:00 +0900
author: ê¹€ì—°ìˆ˜
tags: python sklearn ml spark
excerpt: ì¢€ ë” ë¹ ë¥¸ ML inferenceë¥¼ ìœ„í•´ spark broadcastingì„ ì‚¬ìš©í•´ë´…ë‹ˆë‹¤.
toc: false
use_math: false
# tags: ìë™ ìˆ˜ì§‘ë˜ëŠ” íƒœê·¸ ë„ì–´ì“°ê¸°ë¡œ êµ¬ë¶„, ë°˜ë“œì‹œ ì†Œë¬¸ìë¡œ ì‚¬ìš©
# excerpt: ë©”ì¸ í™”ë©´ì— ë…¸ì¶œë˜ëŠ” postì˜ description
# toc : ëª©ì°¨ê°€ í•„ìš” í•  ê²½ìš° true | false
# use_math : ìˆ˜ì‹ì´ í•„ìš” í•  ê²½ìš°(ìœ— ì²¨ì, ì•„ë«ì²¨ì ë™ì‹œ ì‚¬ìš© ë¶ˆê°€) true | false
# emoji ì‚¬ì´íŠ¸: https://getemoji.com/
---

# Spark Broadcast
## ìš°ë¦¬ì—ê²Œ í•„ìš”í•œ ê²ƒì€ inference íš¨ìœ¨ì„± ğŸ˜
<br/>

> ê¸°ì¡´ python ml ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ë‹¤ëŸ‰ì˜ ë°ì´í„°ë¥¼ ë¹ ë¥´ê²Œ ì²˜ë¦¬ë¥¼ í•´ì•¼ í•  ë•Œ!  <u>Spark broadcasting</u>ì„ ì´ìš©í•´ inference ì†ë„ë¥¼ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

<br/>

### Sparkì˜ ê³µìœ  ë³€ìˆ˜
<hr/>
<br/>

<b>ì•„í”¼ì¹˜ ìŠ¤íŒŒí¬</b>ëŠ” SQL, ë¨¸ì‹ ëŸ¬ë‹ ë“± ì²˜ë¦¬ë¥¼ ìœ„í•œ ê¸°ë³¸ ì œê³µ ëª¨ë“ˆì´ ìˆëŠ” <u>ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬ìš© í†µí•© ë¶„ì„ ì—”ì§„</u>ì…ë‹ˆë‹¤. 

</br>
ì¼ë°˜ì ì¸ ìŠ¤íŒŒí¬ ì—°ì‚°ì´ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‹¤í–‰ë  ë•Œ í•¨ìˆ˜ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë³€ìˆ˜ëŠ” ê° í´ëŸ¬ìŠ¤í„°ì— ë³µì œë˜ê³  ê° ë…¸ë“œ ì—°ì‚°ì—ì„œëŠ” ë…ë¦½ì ì…ë‹ˆë‹¤. í´ëŸ¬ìŠ¤í„° ìƒì—ì„œ ë³€ìˆ˜ë¥¼ ê³µìœ í•˜ëŠ” ê²ƒì€ ë¹„íš¨ìœ¨ì ì´ê¸° ë•Œë¬¸ì¸ë°, ì¼ë°˜ì ì¸ ì—°ì‚° íŒ¨í„´ì„ ì§€ì›í•˜ê¸° ìœ„í•´ ì•„ë˜ì™€ ê°™ì€ ê³µìœ  ë³€ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤
.

- broadcast variables : í° ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ”ë° ì‚¬ìš©
- Accumulators variables : íŠ¹ì • ì»¬ë ‰ì…˜ì˜ ì •ë³´ë¥¼ ì§‘ê³„í•˜ëŠ” ë° ì‚¬ìš©

ì˜¤ëŠ˜ì€ <b>broadcast variables</b>ì— ëŒ€í•˜ì—¬ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.

<br/>

### Spark broadcast ë€?
<hr/>
<br/>

broadcast ë³€ìˆ˜ëŠ” ì½ê¸° ì „ìš© ë³€ìˆ˜ì…ë‹ˆë‹¤. ëª¨ë“  ë…¸ë“œì— í° input ë°ì´í„°ì…‹ì„ ì œê³µí•  ë•Œ íš¨ê³¼ì ì¸ ë°©ë²•ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ì‚¬ìš©í•˜ë©´ íš¨ìœ¨ì ì¸ broadcast ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ê³„ì‚° ë¹„ìš©ì„ ì¤„ì¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

<br/>

ìŠ¤íŒŒí¬ì˜ ì•¡ì…˜ë“¤ì€ ê¸°ë³¸ì ìœ¼ë¡œ ì—¬ëŸ¬ ë‹¨ê³„ì˜ ì§‘í•©ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ”ë°, ìë™ì ìœ¼ë¡œ ê° ë‹¨ê³„ì— í•„ìš”í•œ ê³µìœ  ë³€ìˆ˜ë“¤ì„ broadcastí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

Broadcast ë³€ìˆ˜ëŠ” RDDë‚˜ Dataframeê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ë°ì´í„°ëŠ” serialized ìºì‹±ë˜ê³  deserialized ë˜ì–´ ê° í…ŒìŠ¤í¬ë¡œ ë„˜ì–´ê°„ë‹¤.) 

<br/>
í˜¸ì¶œ ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

```shell
sc = SparkContext()
var = Array(4,5,6) # ì‚¬ìš©í•  ê³µìœ  ë³€ìˆ˜ var

broadcastvar = sc.broadcast(var)
```
ì¼ë‹¨ broadcast variableì´ ë§Œë“¤ì–´ì§€ë©´, í´ëŸ¬ìŠ¤í„°ìƒì˜ ëª¨ë“  í•¨ìˆ˜ì— ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì¦‰, <u>varì€ í•œ ë²ˆ ì´ìƒ ë…¸ë“œì— ì˜¬ë¼ê°€ì§€ ì•Šê²Œ</u> ë©ë‹ˆë‹¤.)

ì°¸ê³ ë¡œ, í•œ ë²ˆ ìƒì„±ëœ broadcastvar ê°ì²´ëŠ” ì´í›„ ìˆ˜ì •ë  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

<br/> 
broadcast ëœ ê°’ì„ ì´ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” <b>value ë©”ì†Œë“œ</b>ë¥¼ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤.

```shell
# value ê°’ì— ì•¡ì„¸ìŠ¤ í•˜ê¸° ìœ„í•¨
broadcastvar.value

# output
> Array(4,5,6)
```

<br/>

## sklearnì— spark broadcastë¥¼ ì ìš©í•´ inference í•˜ê¸°
<hr/>
<br/>

pythonì—ì„œ ê°€ì¥ ë§ì´ ì´ìš©ë˜ëŠ” mechine learning libraryëŠ” sklearnì¼ ê²ƒì…ë‹ˆë‹¤. sklearn ì—ì„œëŠ” ë³´í†µ pandas dataframe ì„ í™œìš©í•œ ë°ì´í„°ë¥¼ fití•˜ê³  predict í•˜ê²Œ ë©ë‹ˆë‹¤. 

ì˜ˆë¥¼ ë“¤ì–´, KNN (K-Nearest Neighbors)ê³¼ ê°™ì€ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ê²Œ ëœë‹¤ë©´ ìš°ë¦¬ëŠ” ê° key ê°’ì— ëŒ€í•œ ê°ê°ì˜ kê°œì˜ neighborsë¥¼ ëª¨ë‘ êµ¬í•´ì•¼í•©ë‹ˆë‹¤. ì¦‰, <b>key ê°’ í•˜ë‚˜í•˜ë‚˜ì— ëª¨ë“  ë°ì´í„°ë¥¼ ì—°ì‚°</b>í•˜ê²Œ ë©ë‹ˆë‹¤.ê²°êµ­ inference ì‹œê°„ì´ ì—„ì²­ë‚˜ê²Œ ê¸¸ì–´ì§ˆ ìˆ˜ ë°–ì— ì—†ëŠ” êµ¬ì¡°ê°€ ë©ë‹ˆë‹¤. 

ì´ëŠ” <b><u>sklearn modelì„ broadcast í•˜ëŠ” ë°©ì‹</u></b>ì„ í™œìš©í•´ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<br/>

ì˜ˆì œ ì½”ë“œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ( knn model ì‚¬ìš© )

```shell
def knn_regressor_broadcast(data_pd, neighbors=100, n_partitions=10, weights = "uniform"):

  # X_train, y_train, X_test, y_test ì˜ ê²½ìš° pandas dataframe í˜•íƒœ
  

  # ëª¨ë¸ fit
  knn = KNeighborsRegressor(n_neighbors = neighbors, weights = weights)
  model = knn.fit(X_train, y_train)
  
  # ì—¬ëŸ¬ ë°°ì¹˜ë¡œ ëŒë¦¬ê¸° ìœ„í•œ í•¨ìˆ˜
  def batch(value):
    yield list(value)
    
  rdd = sc.parallelize(X_test, n_partitions).zipWithIndex()
  b_model = sc.broadcast(model)
  result = rdd.mapPartitions(batch).map(lambda value: ([x[0] for x in value], [x[1] for x in value])).flatMap(lambda x: zip(x[1], b_model.value.predict(x[0])))
  
  result = result.collect()
  result = [x[1] for x in result]
  pred_df = pd.DataFrame({"true":test1, "pred":result})

  return pred_df
```

ìœ„ì™€ ê°™ì´ <b>modelì„ broadcast + rdd test data</b>ë¥¼ ì‚¬ìš©í•˜ì Pandas dataframeì„ ì´ìš©í•´ predictë¥¼ í•˜ì˜€ì„ ë•Œ Runtime errorrkê°€ ë‚¬ë˜ ëª¨ë¸ì„ ì•½ 5ë¶„ ë‚´ì™¸ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤ ğŸ‘ğŸ‘

<br/>

ë¶€ê°€ì ì¸ ì½”ë“œ ì„¤ëª…ì„ ì ì‹œ í•˜ìë©´

mapPartitionsì˜ ê²½ìš° ë‚˜ëˆ ì§„ partitionë‚´ì—ì„œ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê²Œ í•´ì¤ë‹ˆë‹¤
```shell
rdd = sc.parallelize([1, 2, 3, 4], 2)
def f(iterator): yield sum(iterator)
rdd.mapPartitions(f).collect()

# output
> [3, 7]
```
ì¦‰, broadcastëœ ëª¨ë¸ì— test ë°ì´í„°ë¥¼ batch  í˜•íƒœë¡œ ë¶„ì‚° ì²˜ë¦¬ê°€ ê°€ëŠ¥í•´ì§„ë‹¤ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
<br/>

## ì°¸ê³  ìë£Œ
<hr/>

ğŸ‘‰ [About advaced spark programming - spark broadcast](https://www.tutorialspoint.com/apache_spark/advanced_spark_programming.htm)

ğŸ‘‰ [Spark Broadcast Varibales](https://sparkbyexamples.com/spark/spark-broadcast-variables/)
